{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('./dataset/kaggle/train.csv')\n",
    "df_test = pd.read_csv('./dataset/kaggle/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:22: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:53: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:53: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\3966687669.py:22: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  author = re.sub('\\s+', ' ', author.strip().lower())\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\3966687669.py:29: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  author_list = re.split('\\s*&\\s*', author)\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\3966687669.py:31: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  authors = re.split('\\s*,\\s*', author)\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\3966687669.py:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  author_list += re.split('\\s*&\\s*', authors[-1])\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\3966687669.py:37: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  author = ' '.join([re.sub('\\s+', '_', a) for a in author_list])\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\3966687669.py:45: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  topic = ' '.join([re.sub('\\s+', '_', t) for t in topic_list])\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\3966687669.py:53: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  match_obj = re.search('([\\w]+),\\s+([\\d]+)\\s+([\\w]+)\\s+([\\d]+)\\s+([\\d]+):([\\d]+):([\\d]+)', date_time)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def preprocessor(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "\n",
    "    # find title\n",
    "    title = soup.body.h1.string.strip().lower()\n",
    "\n",
    "    # find author\n",
    "    article_info = soup.head.find('div', {'class': 'article-info'})\n",
    "    author_name = article_info.find('span', {'class': 'author_name'})\n",
    "    if author_name != None:\n",
    "        author = author_name.get_text()\n",
    "    elif article_info.span != None:\n",
    "        author = article_info.span.string\n",
    "    else:\n",
    "        author = article_info.a.string\n",
    "\n",
    "    # clean author\n",
    "    author = re.sub('\\s+', ' ', author.strip().lower())\n",
    "    if author.startswith('by '):\n",
    "        author = author[3:]\n",
    "    author = re.sub('&.*;', '&', author.replace(' and ', ' & '))\n",
    "\n",
    "    author_list = []\n",
    "    if author.find(',') == -1:\n",
    "        author_list = re.split('\\s*&\\s*', author)\n",
    "    else:\n",
    "        authors = re.split('\\s*,\\s*', author)\n",
    "        if authors[-1].find('&') == -1 or len(authors[-1].split('&')[-1].strip().split()) > 3:\n",
    "            author_list.append(authors[0])\n",
    "        else:\n",
    "            author_list += authors[:-1]\n",
    "            author_list += re.split('\\s*&\\s*', authors[-1])\n",
    "    author = ' '.join([re.sub('\\s+', '_', a) for a in author_list])\n",
    "\n",
    "    # find channel\n",
    "    channel = soup.body.article['data-channel'].strip().lower()\n",
    "\n",
    "    # find topic\n",
    "    a_list = soup.body.find('footer', {'class': 'article-topics'}).find_all('a')\n",
    "    topic_list = [a.string.strip().lower() for a in a_list]\n",
    "    topic = ' '.join([re.sub('\\s+', '_', t) for t in topic_list])\n",
    "\n",
    "    # find datetime\n",
    "    article_info = soup.head.find('div', {'class': 'article-info'})\n",
    "    try:\n",
    "        date_time = article_info.time['datetime']\n",
    "    except:\n",
    "        date_time = 'Wed, 10 Oct 2014 15:00:43'\n",
    "    match_obj = re.search('([\\w]+),\\s+([\\d]+)\\s+([\\w]+)\\s+([\\d]+)\\s+([\\d]+):([\\d]+):([\\d]+)', date_time)\n",
    "    day, date, month, year, hour, minute, second = match_obj.groups()\n",
    "    day, month = day.lower(), month.lower()\n",
    "\n",
    "    # find content\n",
    "    content = soup.body.find('section', {'class': 'article-content'}).get_text()\n",
    "    content_len = len(content)\n",
    "\n",
    "    # find see also\n",
    "    num_see_also = len(re.findall('see also', content.lower()))\n",
    "\n",
    "    # find image\n",
    "    num_image = len(soup.body.find_all('img'))\n",
    "\n",
    "    # find a\n",
    "    num_a = len(soup.body.find_all('a'))\n",
    "\n",
    "    return title, author, channel, topic, day, date, month, year, \\\n",
    "        hour, minute, second, content_len, num_see_also, num_image, num_a\n",
    "\n",
    "\n",
    "feature_list = []\n",
    "for text in df_train['Page content']:\n",
    "    feature_list.append(preprocessor(text))\n",
    "for text in df_test['Page content']:\n",
    "    feature_list.append(preprocessor(text))\n",
    "\n",
    "df_combine = pd.DataFrame(\n",
    "    feature_list,\n",
    "    columns=['Title', 'Author', 'Channel', 'Topic', 'Day', 'Date', 'Month', 'Year',\n",
    "             'Hour', 'Minute', 'Second', 'Content_Len', 'Num_See_Also', 'Num_Image', 'Num_A']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Content_Len</th>\n",
       "      <th>Num_See_Also</th>\n",
       "      <th>Num_Image</th>\n",
       "      <th>Num_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nasa's grand challenge: stop asteroids from de...</td>\n",
       "      <td>clara_moskowitz</td>\n",
       "      <td>world</td>\n",
       "      <td>asteroid asteroids challenge earth space u.s. ...</td>\n",
       "      <td>wed</td>\n",
       "      <td>19</td>\n",
       "      <td>jun</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "      <td>3591</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google's new open source patent pledge: we won...</td>\n",
       "      <td>christina_warren</td>\n",
       "      <td>tech</td>\n",
       "      <td>apps_and_software google open_source opn_pledg...</td>\n",
       "      <td>thu</td>\n",
       "      <td>28</td>\n",
       "      <td>mar</td>\n",
       "      <td>2013</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>1843</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ballin': 2014 nfl draft picks get to choose th...</td>\n",
       "      <td>sam_laird</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>entertainment nfl nfl_draft sports television</td>\n",
       "      <td>wed</td>\n",
       "      <td>07</td>\n",
       "      <td>may</td>\n",
       "      <td>2014</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>6646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cameraperson fails deliver slapstick laughs</td>\n",
       "      <td>sam_laird</td>\n",
       "      <td>watercooler</td>\n",
       "      <td>sports video videos watercooler</td>\n",
       "      <td>fri</td>\n",
       "      <td>11</td>\n",
       "      <td>oct</td>\n",
       "      <td>2013</td>\n",
       "      <td>02</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nfl star helps young fan prove friendship with...</td>\n",
       "      <td>connor_finnegan</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>entertainment instagram instagram_video nfl sp...</td>\n",
       "      <td>thu</td>\n",
       "      <td>17</td>\n",
       "      <td>apr</td>\n",
       "      <td>2014</td>\n",
       "      <td>03</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>8919</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title            Author  \\\n",
       "0  nasa's grand challenge: stop asteroids from de...   clara_moskowitz   \n",
       "1  google's new open source patent pledge: we won...  christina_warren   \n",
       "2  ballin': 2014 nfl draft picks get to choose th...         sam_laird   \n",
       "3        cameraperson fails deliver slapstick laughs         sam_laird   \n",
       "4  nfl star helps young fan prove friendship with...   connor_finnegan   \n",
       "\n",
       "         Channel                                              Topic  Day Date  \\\n",
       "0          world  asteroid asteroids challenge earth space u.s. ...  wed   19   \n",
       "1           tech  apps_and_software google open_source opn_pledg...  thu   28   \n",
       "2  entertainment      entertainment nfl nfl_draft sports television  wed   07   \n",
       "3    watercooler                    sports video videos watercooler  fri   11   \n",
       "4  entertainment  entertainment instagram instagram_video nfl sp...  thu   17   \n",
       "\n",
       "  Month  Year Hour Minute Second  Content_Len  Num_See_Also  Num_Image  Num_A  \n",
       "0   jun  2013   15     04     30         3591             4          1     21  \n",
       "1   mar  2013   17     40     55         1843             1          1     16  \n",
       "2   may  2014   19     15     20         6646             1          1      9  \n",
       "3   oct  2013   02     26     50         1821             1          0     11  \n",
       "4   apr  2014   03     31     43         8919             1         51     14  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_map = {'mon': 1, 'tue': 2, 'wed': 3,\n",
    "           'thu': 4, 'fri': 5, 'sat': 6, 'sun': 7}\n",
    "month_map = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "             'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "\n",
    "df_copy = df_combine.copy()\n",
    "df_copy['Day'] = df_copy['Day'].map(day_map)\n",
    "df_copy['Month'] = df_copy['Month'].map(month_map)\n",
    "\n",
    "df_copy = df_copy.drop(columns=['Title', 'Channel', 'Minute', 'Second', 'Num_See_Also', 'Num_Image', 'Num_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Content_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clara_moskowitz</td>\n",
       "      <td>asteroid asteroids challenge earth space u.s. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "      <td>3591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>christina_warren</td>\n",
       "      <td>apps_and_software google open_source opn_pledg...</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>17</td>\n",
       "      <td>1843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sam_laird</td>\n",
       "      <td>entertainment nfl nfl_draft sports television</td>\n",
       "      <td>3</td>\n",
       "      <td>07</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>19</td>\n",
       "      <td>6646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sam_laird</td>\n",
       "      <td>sports video videos watercooler</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>02</td>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>connor_finnegan</td>\n",
       "      <td>entertainment instagram instagram_video nfl sp...</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>03</td>\n",
       "      <td>8919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Author                                              Topic  Day  \\\n",
       "0   clara_moskowitz  asteroid asteroids challenge earth space u.s. ...    3   \n",
       "1  christina_warren  apps_and_software google open_source opn_pledg...    4   \n",
       "2         sam_laird      entertainment nfl nfl_draft sports television    3   \n",
       "3         sam_laird                    sports video videos watercooler    5   \n",
       "4   connor_finnegan  entertainment instagram instagram_video nfl sp...    4   \n",
       "\n",
       "  Date  Month  Year Hour  Content_Len  \n",
       "0   19      6  2013   15         3591  \n",
       "1   28      3  2013   17         1843  \n",
       "2   07      5  2014   19         6646  \n",
       "3   11     10  2013   02         1821  \n",
       "4   17      4  2014   03         8919  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\4085094747.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  return re.split('\\s+', text.strip())\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\4085094747.py:18: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub(\"([\\w]+)'[\\w]+\",\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\4085094747.py:20: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  text = re.sub('\\.', '', text)\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\4085094747.py:21: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub('[^\\w]+', ' ', text)\n",
      "C:\\Users\\Cark C3 PVT\\AppData\\Local\\Temp\\ipykernel_9548\\4085094747.py:23: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  return [wnl.lemmatize(s) for s in re.split('\\s+', text.strip())]\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Cark C3\n",
      "[nltk_data]     PVT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Cark C3\n",
      "[nltk_data]     PVT\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    if type(text) == np.ndarray:\n",
    "        text = text[0]\n",
    "    return re.split('\\s+', text.strip())\n",
    "\n",
    "\n",
    "def tokenizer_wnl(text):\n",
    "    if type(text) == np.ndarray:\n",
    "        text = text[0]\n",
    "    text = re.sub(\"([\\w]+)'[\\w]+\",\n",
    "                  (lambda match_obj: match_obj.group(1)), text)\n",
    "    text = re.sub('\\.', '', text)\n",
    "    text = re.sub('[^\\w]+', ' ', text)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    return [wnl.lemmatize(s) for s in re.split('\\s+', text.strip())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "trans_forest = ColumnTransformer(\n",
    "    [('Author', CountVectorizer(tokenizer=tokenizer, lowercase=False), [0]),\n",
    "     ('Topic', CountVectorizer(tokenizer=tokenizer_wnl, lowercase=False), [1])],\n",
    "    n_jobs=-1,\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "trans_other = ColumnTransformer(\n",
    "    [('Author', 'drop', [0]),\n",
    "     ('Topic', CountVectorizer(tokenizer=tokenizer_wnl, lowercase=False), [1])],\n",
    "    n_jobs=-1,\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_raw = df_copy.values[:df_train.shape[0]]\n",
    "y_train_raw = (df_train['Popularity'].values == 1).astype(int)\n",
    "X_test = df_copy.values[df_train.shape[0]:]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_raw, y_train_raw, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def training(clf):\n",
    "    cv_results = cross_validate(clf, X_train_raw, y_train_raw,\n",
    "                                scoring='roc_auc', return_train_score=True, return_estimator=True)\n",
    "    print('train score: {:.5f} (+/-{:.5f})'.format(\n",
    "        np.mean(cv_results['train_score']), np.std(cv_results['train_score'])))\n",
    "    print('valid score: {:.5f} (+/-{:.5f})'.format(\n",
    "        np.mean(cv_results['test_score']), np.std(cv_results['test_score'])))\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('train score: {:.5f}'.format(roc_auc_score(\n",
    "        y_train, clf.predict_proba(X_train)[:, 1])))\n",
    "    print('valid score: {:.5f}'.format(roc_auc_score(\n",
    "        y_valid, clf.predict_proba(X_valid)[:, 1])))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1575\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 596\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493172 -> initscore=-0.027315\n",
      "[LightGBM] [Info] Start training from score -0.027315\n",
      "[LightGBM] [Info] Number of positive: 10905, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1550\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493127 -> initscore=-0.027496\n",
      "[LightGBM] [Info] Start training from score -0.027496\n",
      "[LightGBM] [Info] Number of positive: 10905, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1552\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 587\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493127 -> initscore=-0.027496\n",
      "[LightGBM] [Info] Start training from score -0.027496\n",
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1557\n",
      "[LightGBM] [Info] Number of data points in the train set: 22115, number of used features: 588\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493149 -> initscore=-0.027404\n",
      "[LightGBM] [Info] Start training from score -0.027404\n",
      "[LightGBM] [Info] Number of positive: 10906, number of negative: 11209\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1558\n",
      "[LightGBM] [Info] Number of data points in the train set: 22115, number of used features: 587\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493149 -> initscore=-0.027404\n",
      "[LightGBM] [Info] Start training from score -0.027404\n",
      "train score: 0.66998 (+/-0.00274)\n",
      "valid score: 0.60266 (+/-0.00800)\n",
      "[LightGBM] [Info] Number of positive: 10885, number of negative: 11229\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1567\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 592\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492222 -> initscore=-0.031114\n",
      "[LightGBM] [Info] Start training from score -0.031114\n",
      "train score: 0.67154\n",
      "valid score: 0.59769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = Pipeline([('ct', trans_other),\n",
    "                 ('clf', LGBMClassifier(random_state=0, learning_rate=0.009, n_estimators=300))])\n",
    "lgbm = training(lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.00000 (+/-0.00000)\n",
      "valid score: 0.58552 (+/-0.00989)\n",
      "train score: 1.00000\n",
      "valid score: 0.58378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = Pipeline([('ct', trans_forest),\n",
    "                   ('clf', RandomForestClassifier(n_jobs=-1, random_state=0, n_estimators=300))])\n",
    "forest = training(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.81282 (+/-0.00500)\n",
      "valid score: 0.58232 (+/-0.01309)\n",
      "train score: 0.81618\n",
      "valid score: 0.57805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost = Pipeline([('ct', trans_other),\n",
    "                    ('clf', XGBClassifier(verbosity=0, n_estimators=300))])\n",
    "xgboost = training(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m      4\u001b[0m catboost \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m'\u001b[39m, trans_other),\n\u001b[0;32m      5\u001b[0m                      (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, CatBoostClassifier(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m290\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.06\u001b[39m))])\n\u001b[0;32m      6\u001b[0m catboost \u001b[38;5;241m=\u001b[39m training(catboost)\n",
      "File \u001b[1;32mc:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001b[0;32m      3\u001b[0m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001b[0;32m      4\u001b[0m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001b[0;32m      5\u001b[0m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001b[0;32m      6\u001b[0m )  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VERSION \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeaturesData\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFstrType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEShapCalcType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionGrouping\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPool\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRanker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatboostError\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomMetric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomObjective\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\core.py:45\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuiltinMetric\n",
      "File \u001b[1;32mc:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\catboost\\plot_helpers.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[0;32m      6\u001b[0m fspath \u001b[38;5;241m=\u001b[39m _catboost\u001b[38;5;241m.\u001b[39mfspath\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_plot_offline\u001b[39m(figs):\n",
      "File \u001b[1;32m_catboost.pyx:1\u001b[0m, in \u001b[0;36minit _catboost\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost = Pipeline([('ct', trans_other),\n",
    "                     ('clf', CatBoostClassifier(verbose=False, eval_metric='AUC', n_estimators=290, learning_rate=0.06))])\n",
    "catboost = training(catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: catboost in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (3.1.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\cark c3 pvt\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\njoblib.externals.loky.process_executor._RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 426, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nModuleNotFoundError: No module named 'numpy._core.numeric'\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 66, in inner_f\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 423, in fit\n    return super().fit(X, transformed_y, **fit_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 104, in fit\n    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 40, in _fit_single_estimator\n    estimator.fit(X, y, **fit_params)\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 469, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 406, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 976, in fit_transform\n    result = self._call_func_on_transformers(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n    yield from self._retrieve()\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1754, in _retrieve\n    self._raise_error_fast()\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1789, in _raise_error_fast\n    error_job.get_result(self.timeout)\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 745, in get_result\n    return self._return_or_raise()\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 763, in _return_or_raise\n    raise self._result\njoblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VotingClassifier\n\u001b[0;32m      2\u001b[0m voting \u001b[38;5;241m=\u001b[39m VotingClassifier([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, lgbm), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforest\u001b[39m\u001b[38;5;124m'\u001b[39m, forest)],\n\u001b[0;32m      3\u001b[0m                           voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m, weights\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m voting \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoting\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(clf)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining\u001b[39m(clf):\n\u001b[1;32m----> 6\u001b[0m     cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain score: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m (+/-\u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m      9\u001b[0m         np\u001b[38;5;241m.\u001b[39mmean(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_score\u001b[39m\u001b[38;5;124m'\u001b[39m]), np\u001b[38;5;241m.\u001b[39mstd(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_score\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid score: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m (+/-\u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     11\u001b[0m         np\u001b[38;5;241m.\u001b[39mmean(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m'\u001b[39m]), np\u001b[38;5;241m.\u001b[39mstd(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n",
      "File \u001b[1;32mc:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\njoblib.externals.loky.process_executor._RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 426, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nModuleNotFoundError: No module named 'numpy._core.numeric'\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 66, in inner_f\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 423, in fit\n    return super().fit(X, transformed_y, **fit_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 104, in fit\n    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 40, in _fit_single_estimator\n    estimator.fit(X, y, **fit_params)\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 469, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 406, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 976, in fit_transform\n    result = self._call_func_on_transformers(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n    yield from self._retrieve()\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1754, in _retrieve\n    self._raise_error_fast()\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1789, in _raise_error_fast\n    error_job.get_result(self.timeout)\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 745, in get_result\n    return self._return_or_raise()\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Cark C3 PVT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 763, in _return_or_raise\n    raise self._result\njoblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting = VotingClassifier([('lgbm', lgbm), ('forest', forest), ('catboost', catboost)],\n",
    "                          voting='soft', weights=[1, 0.2, 0.05])\n",
    "voting = training(voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = voting\n",
    "\n",
    "y_score = best_model.predict_proba(X_test)[:, 1]\n",
    "df_pred = pd.DataFrame({'Id': df_test['Id'], 'Popularity': y_score})\n",
    "df_pred.to_csv('test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
